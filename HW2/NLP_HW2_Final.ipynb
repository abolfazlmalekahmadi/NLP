{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "پردازش زبان طبیعی (نیم‌سال دوم 01-02)\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "        <h1 style=\"text-align: center\">\n",
    "        تمرین دوم\n",
    "        </h1>\n",
    "\t\t<h2 style=\"text-align: center\">\n",
    "        محراب مرادزاده: 401201198\n",
    "\t\t<br>\n",
    "\t\tابوالفضل ملک احمدی: 401205167\n",
    "\t\t<br>\n",
    "\t\tعلی درخشش: 401203252\n",
    "\t\t</h2>\t\t \n",
    "\t\t</h3>\n",
    "            \n",
    "  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "تشخیص کلمات غیرقانونی\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "        برای مشاهده صحیح این نوت بوک فونت XB Zar را بر روی کامپیوتر خود داشته باشید.\n",
    "        <br>        \n",
    "        <br>\n",
    "        در این نوت بوک ما تشخیص کلمات غیرمجاز را با استفاده از لیستی از کلمات غیرقانونی انجام میدهیم.\n",
    "        <br>\n",
    "        به عنوان مثال در جدول زیر با کلمات غیرقانونی {قاشق، چنگال، تفنگ و تیر} تعدادی متن ورودی بررسی شده است.\n",
    "        <br>\n",
    "        <br>\n",
    "        <table style=\"width: 100%; font-size: 0.9em\">\n",
    "    <thead>\n",
    "      <tr>\n",
    "        <th style=\"text-align:center\">متن ورودی</th>\n",
    "        <th style=\"text-align:center\">خروجی</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr>\n",
    "        <td style=\"text-align:center\">این <span style='color:tomato'>&تف...%ن8گ#</span> را فروختم.</td>\n",
    "        <td style=\"text-align:center\">{'تفنگ': [(4, 14)]}</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"text-align:center\">با <span style='color:tomato'>ق*bاaشق </span> و <span style='color:tomato'>fچ^!نگ4ال </span> غذا خوردم.</td>\n",
    "        <td style=\"text-align:center\">{'قاشق': [(3, 9)], 'چنگال': [(13, 21)]}</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"text-align:center\">من <span style='color:tomato'>قاشق </span>&nbsp&nbsp&nbspدوست  <span style='color:tomato'>قاش*ق </span> دارم.</td>\n",
    "        <td style=\"text-align:center\">{'قاشق': [(3, 6), (15, 19)]}</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"text-align:center\">من <span style='color:tomato'>قاشق </span> و <span style='color:tomato'>قاشق،قاشق،قاشق </span> را در جیب دارم.</td>\n",
    "        <td style=\"text-align:center\">{'قاشق': [(3, 6), (10, 23)]}</td>\n",
    "      </tr>\n",
    "       <tr>\n",
    "        <td style=\"text-align:center\">من <span style='color:tomato'>قا3شق </span> و <span style='color:tomato'>قا3شق </span> را <span style='color:tomato'>قاشق </span> دارم.</td>\n",
    "        <td style=\"text-align:center\">{'قاشق': [(20, 23), (3, 7), (11, 15)]}</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"text-align:center\"><span style='color:tomato'>قاشق </span> من با <span style='color:tomato'>قا///شق </span> تو دوست است.</td>\n",
    "        <td style=\"text-align:center\">{'قاشق': [(0, 3), (11, 17)]}</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"text-align:center\"><span style='color:tomato'>قاشق </span> من <span style='color:tomato'>تی\\u843ر </span> هوایی میزند.</td>\n",
    "        <td style=\"text-align:center\">{'قاشق': [(0, 3)], 'تیر': [(8, 15)]}</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"text-align:center\">من <span style='color:tomato'>قاشق </span> <span style='color:tomato'>قاشق </span> <span style='color:tomato'>قاشق </span> دارم.</td>\n",
    "        <td style=\"text-align:center\">{'قاشق': [(3, 6), (8, 11), (13, 16)]}</td>\n",
    "      </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "Code Versions\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "       در این قسمت کدهای نوشته شده در طول تعطیلات عید نوروز برای این تمرین که هر کدام فیچری به دیتکتور اضافه میکند را بررسی میکنیم:\n",
    "\t   <br>\n",
    "\t   به تمامی ورژن ها 8 مثال مشابه مثال های بالا داده میشود تا ارزیابی روی ورژن ها صورت گیرد. \n",
    "        <br>\n",
    "\t\tهمچنین ارورهایی که در کدهای اولیه میبینید به خاطر این است که ورژن های اولیه بعضی از ورودی ها را هندل نمیکنند.\n",
    "\t\t<br>\n",
    "\t\tدر نهایت توضیحات خط به خط کد در ورژن نهایی داده میشود.\n",
    "\t\t<br>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "ورژن ۱\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "در این ورژن ایده کلی برای شروع شکل گرفته و نوشته شده است\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "{'قاشق': (4, 10)}\n",
      "==================================================\n",
      "{'قاشق': (3, 12)}\n",
      "==================================================\n",
      "{'قاشق': (3, 6)}\n",
      "==================================================\n",
      "{'قاشق': (3, 6)}\n",
      "==================================================\n",
      "{'قاشق': (20, 23)}\n",
      "==================================================\n",
      "{'قاشق': (0, 3)}\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "incomplete escape \\u843 at position 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs:\n\u001b[0;32m     54\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[1;32m---> 55\u001b[0m     \u001b[39mprint\u001b[39m(illegal_extractor(\u001b[39minput\u001b[39;49m,[\u001b[39m'\u001b[39;49m\u001b[39mچنگال\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mقاشق\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n",
      "Cell \u001b[1;32mIn[37], line 29\u001b[0m, in \u001b[0;36millegal_extractor\u001b[1;34m(input_text, input_list)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mfor\u001b[39;00m scrambled_token \u001b[39min\u001b[39;00m scrambled_tokens:\n\u001b[0;32m     28\u001b[0m     scrambled_chars_str \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,scrambled_token)\n\u001b[1;32m---> 29\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(re\u001b[39m.\u001b[39;49msub(\u001b[39m'\u001b[39;49m\u001b[39m[\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mscrambled_chars_str\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, scrambled_token)) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     30\u001b[0m         remaked \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mscrambled_chars_str\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     31\u001b[0m                                    scrambled_token)\n\u001b[0;32m     32\u001b[0m         scrambled_dict[remaked] \u001b[39m=\u001b[39m scrambled_token\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\regex\\regex.py:277\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags, pos, endpos, concurrent, timeout, ignore_unused, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pos\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, endpos\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    271\u001b[0m   concurrent\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ignore_unused\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    272\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the string obtained by replacing the leftmost (or rightmost with a\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[39m    reverse pattern) non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[39m    replacement repl. repl can be either a string or a callable; if a string,\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39m    backslash escapes in it are processed; if a callable, it's passed the match\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39m    object and must return a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     pat \u001b[39m=\u001b[39m _compile(pattern, flags, ignore_unused, kwargs, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    278\u001b[0m     \u001b[39mreturn\u001b[39;00m pat\u001b[39m.\u001b[39msub(repl, string, count, pos, endpos, concurrent, timeout)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\regex\\regex.py:546\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags, ignore_unused, kwargs, cache_it)\u001b[0m\n\u001b[0;32m    543\u001b[0m         caught_exception \u001b[39m=\u001b[39m e\n\u001b[0;32m    545\u001b[0m     \u001b[39mif\u001b[39;00m caught_exception:\n\u001b[1;32m--> 546\u001b[0m         \u001b[39mraise\u001b[39;00m error(caught_exception\u001b[39m.\u001b[39mmsg, caught_exception\u001b[39m.\u001b[39mpattern,\n\u001b[0;32m    547\u001b[0m           caught_exception\u001b[39m.\u001b[39mpos)\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m source\u001b[39m.\u001b[39mat_end():\n\u001b[0;32m    550\u001b[0m     \u001b[39mraise\u001b[39;00m error(\u001b[39m\"\u001b[39m\u001b[39munbalanced parenthesis\u001b[39m\u001b[39m\"\u001b[39m, pattern, source\u001b[39m.\u001b[39mpos)\n",
      "\u001b[1;31merror\u001b[0m: incomplete escape \\u843 at position 3"
     ]
    }
   ],
   "source": [
    "# version 1\n",
    "\n",
    "\n",
    "import regex as re\n",
    "from hazm import word_tokenize\n",
    "\n",
    "def illegal_extractor(input_text, input_list):\n",
    "    tokens = input_text.split(' ')\n",
    "#     print('all tokens : ', tokens)\n",
    "    \n",
    "    legal_tokens = []\n",
    "    scrambled_tokens = []\n",
    "    \n",
    "    # legal extraction\n",
    "    for token in tokens:\n",
    "        if len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 0:\n",
    "            scrambled_tokens.append(token)\n",
    "        elif len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 1:\n",
    "            legal_tokens.append(token)\n",
    "        else:\n",
    "            raise Exception(\"*** Error in legal_illegal extraction***\")            \n",
    "    \n",
    "    span_dict = {}\n",
    "    scrambled_dict = {} #  remake : scrambled\n",
    "    # illegal = all_tokens - legal_tokens\n",
    "    for scrambled_token in scrambled_tokens:\n",
    "        \n",
    "        scrambled_chars_str = re.sub('[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]', '',scrambled_token)\n",
    "        if len(re.sub('['+scrambled_chars_str+']', '', scrambled_token)) != 0:\n",
    "            remaked = re.sub('['+scrambled_chars_str+']', '',\n",
    "                                       scrambled_token)\n",
    "            scrambled_dict[remaked] = scrambled_token\n",
    "            \n",
    "    for user_word in input_list:\n",
    "        if user_word in legal_tokens:\n",
    "            start_index = input_text.find(user_word)\n",
    "            stop_index = start_index + len(user_word) - 1\n",
    "            span_dict[user_word] = (start_index, stop_index)\n",
    "            \n",
    "        elif user_word in scrambled_dict.keys():\n",
    "            start_index = input_text.find(scrambled_dict[user_word])\n",
    "            stop_index = start_index + len(scrambled_dict[user_word]) - 1\n",
    "            span_dict[user_word] = (start_index, stop_index)\n",
    "                \n",
    "    return span_dict\n",
    "\n",
    "\n",
    "inputs = ['این قا#3dشق را فروختم.', \n",
    "          'با قا833gheشق و چن^گsd6yالg غذا خوردم.',\n",
    "         'من قاشق قاشق قاشق دارم.',\n",
    "         'من قاشق و قاشق،قاشق،قاشق را در جیب دارم.',\n",
    "         'من قا3شق و قا3شق را قاشق دارم.',\n",
    "         'قاشق من با قا///شق تو دوست است.',\n",
    "         'قاشق من چن\\\\u843گال هوایی میزند.',\n",
    "         'من قاشق         دوست قا*شق دارم.']\n",
    "\n",
    "for input in inputs:\n",
    "    print('='*50)\n",
    "    print(illegal_extractor(input,['چنگال','قاشق']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "ورژن ۲\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "        به این ورژن فیچر تکرار در ورودی غیر مجاز اضافه شده است .\n",
    "        <br>\n",
    "\t\tبه این صورت که اگر ورودی غیرمجاز به یک صورت در متن تکرار شود کد قابلیت شناسایی تمام تکرار های آن را داشته باشد\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "{'قاشق': [(4, 10)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 12)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6), (8, 11), (13, 16)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6)]}\n",
      "==================================================\n",
      "{'قاشق': [(20, 23), (3, 7), (11, 15)]}\n",
      "==================================================\n",
      "{'قاشق': [(0, 3), (11, 17)]}\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "incomplete escape \\u843 at position 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 91\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs:\n\u001b[0;32m     90\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[1;32m---> 91\u001b[0m     \u001b[39mprint\u001b[39m(illegal_extractor(\u001b[39minput\u001b[39;49m,[\u001b[39m'\u001b[39;49m\u001b[39mچنگال\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mقاشق\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n",
      "Cell \u001b[1;32mIn[39], line 33\u001b[0m, in \u001b[0;36millegal_extractor\u001b[1;34m(input_text, input_list, dict_out)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m scrambled_token \u001b[39min\u001b[39;00m scrambled_tokens:\n\u001b[0;32m     32\u001b[0m     scrambled_chars_str \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,scrambled_token)\n\u001b[1;32m---> 33\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(re\u001b[39m.\u001b[39;49msub(\u001b[39m'\u001b[39;49m\u001b[39m[\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m+\u001b[39;49mscrambled_chars_str\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m]\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, scrambled_token)) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     34\u001b[0m         remaked \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mscrambled_chars_str\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     35\u001b[0m                                    scrambled_token)\n\u001b[0;32m     36\u001b[0m         df_scrambled_indx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\regex\\regex.py:277\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags, pos, endpos, concurrent, timeout, ignore_unused, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pos\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, endpos\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    271\u001b[0m   concurrent\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ignore_unused\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    272\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the string obtained by replacing the leftmost (or rightmost with a\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[39m    reverse pattern) non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[39m    replacement repl. repl can be either a string or a callable; if a string,\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39m    backslash escapes in it are processed; if a callable, it's passed the match\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39m    object and must return a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     pat \u001b[39m=\u001b[39m _compile(pattern, flags, ignore_unused, kwargs, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    278\u001b[0m     \u001b[39mreturn\u001b[39;00m pat\u001b[39m.\u001b[39msub(repl, string, count, pos, endpos, concurrent, timeout)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\regex\\regex.py:546\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags, ignore_unused, kwargs, cache_it)\u001b[0m\n\u001b[0;32m    543\u001b[0m         caught_exception \u001b[39m=\u001b[39m e\n\u001b[0;32m    545\u001b[0m     \u001b[39mif\u001b[39;00m caught_exception:\n\u001b[1;32m--> 546\u001b[0m         \u001b[39mraise\u001b[39;00m error(caught_exception\u001b[39m.\u001b[39mmsg, caught_exception\u001b[39m.\u001b[39mpattern,\n\u001b[0;32m    547\u001b[0m           caught_exception\u001b[39m.\u001b[39mpos)\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m source\u001b[39m.\u001b[39mat_end():\n\u001b[0;32m    550\u001b[0m     \u001b[39mraise\u001b[39;00m error(\u001b[39m\"\u001b[39m\u001b[39munbalanced parenthesis\u001b[39m\u001b[39m\"\u001b[39m, pattern, source\u001b[39m.\u001b[39mpos)\n",
      "\u001b[1;31merror\u001b[0m: incomplete escape \\u843 at position 3"
     ]
    }
   ],
   "source": [
    "# version 2\n",
    "\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def illegal_extractor(input_text, input_list, dict_out = True):\n",
    "    df_scrambled = pd.DataFrame(columns = ['remake', 'scrambled'])\n",
    "    tokens = input_text.split(' ')\n",
    "    \n",
    "    legal_tokens = []\n",
    "    scrambled_tokens = []\n",
    "    \n",
    "    # legal extraction\n",
    "    for token in tokens:\n",
    "        if len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 0:\n",
    "            scrambled_tokens.append(token)\n",
    "        elif len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 1:\n",
    "            legal_tokens.append(token)\n",
    "        else:\n",
    "            raise Exception(\"*** Error in legal_illegal extraction***\")            \n",
    "    \n",
    "    df_span = pd.DataFrame(columns = ['illegal', 'span'])\n",
    "    span_dict = {}\n",
    "    df_span_indx = -1\n",
    "    df_scrambled_indx = -1\n",
    "    \n",
    "    last_legal = {} # last index for last stored word for multiple same values\n",
    "    last_scrambled = {} # end index of last stored word for multiple same values\n",
    "    for scrambled_token in scrambled_tokens:\n",
    "        \n",
    "        scrambled_chars_str = re.sub('[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]', '',scrambled_token)\n",
    "        if len(re.sub('['+scrambled_chars_str+']', '', scrambled_token)) != 0:\n",
    "            remaked = re.sub('['+scrambled_chars_str+']', '',\n",
    "                                       scrambled_token)\n",
    "            df_scrambled_indx += 1\n",
    "            df_scrambled.loc[df_scrambled_indx] = (remaked, scrambled_token)\n",
    "        \n",
    "    for user_word in input_list:\n",
    "        if user_word in legal_tokens:\n",
    "            span_list = []\n",
    "            for _ in range(legal_tokens.count(user_word)):\n",
    "                start_search = 0\n",
    "                if user_word in last_legal.keys():\n",
    "                    start_search = last_legal[user_word]\n",
    "                start_index = input_text.find(user_word, start_search)\n",
    "                stop_index = start_index + len(user_word) - 1\n",
    "                last_legal[user_word] = stop_index\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "                \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "            \n",
    "        # elif --> changed to if --> word can be in both legal_tokens and scrambled   \n",
    "        if user_word in df_scrambled.remake.values:\n",
    "            span_list = []\n",
    "            for word in df_scrambled[df_scrambled.remake == user_word]['scrambled']:\n",
    "                start_search = 0\n",
    "                if word in last_scrambled.keys():\n",
    "                    start_search = last_scrambled[word]\n",
    "                start_index = input_text.find(word, start_search)\n",
    "                stop_index = start_index + len(word) - 1\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "                last_scrambled[word] = stop_index\n",
    "            \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "    \n",
    "    if not dict_out:\n",
    "        return df_span\n",
    "    \n",
    "    ## Turn dataframe to dict\n",
    "    for item in df_span.iterrows():\n",
    "        span_dict[item[1][0]] = item[1][1]\n",
    "    return span_dict\n",
    "\n",
    "\n",
    "inputs = ['این قا#3dشق را فروختم.', \n",
    "          'با قا833gheشق و چن^گsd6yالg غذا خوردم.',\n",
    "         'من قاشق قاشق قاشق دارم.',\n",
    "         'من قاشق و قاشق،قاشق،قاشق را در جیب دارم.',\n",
    "         'من قا3شق و قا3شق را قاشق دارم.',\n",
    "         'قاشق من با قا///شق تو دوست است.',\n",
    "         'قاشق من چن\\\\u843گال هوایی میزند.',\n",
    "         'من قاشق         دوست قا*شق دارم.']\n",
    "\n",
    "for input in inputs:\n",
    "    print('='*50)\n",
    "    print(illegal_extractor(input,['چنگال','قاشق']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "ورژن ۳\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "در این ورژن یکی از مشکل های رجکس که وجود بک اسلش در ورودی بود حل شده است به این صورت که اگر در ورودی در کلمه غیر مجاز بک اسلش وجود داشته باشد کد قابلیت شناسایی آن را داشته و به مشکل نخورد. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "{'قاشق': [(4, 10)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 12)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6), (8, 11), (13, 16)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6)]}\n",
      "==================================================\n",
      "{'قاشق': [(20, 23), (3, 7), (11, 15)]}\n",
      "==================================================\n",
      "{'قاشق': [(0, 3), (11, 17)]}\n",
      "==================================================\n",
      "{'چنگال': [(8, 17)], 'قاشق': [(0, 3)]}\n",
      "==================================================\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "unterminated character set at position 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 96\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39min\u001b[39;00m inputs:\n\u001b[0;32m     95\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m50\u001b[39m)\n\u001b[1;32m---> 96\u001b[0m     \u001b[39mprint\u001b[39m(illegal_extractor(\u001b[39minput\u001b[39;49m,[\u001b[39m'\u001b[39;49m\u001b[39mچنگال\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mقاشق\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n",
      "Cell \u001b[1;32mIn[40], line 35\u001b[0m, in \u001b[0;36millegal_extractor\u001b[1;34m(input_text, input_list, dict_out)\u001b[0m\n\u001b[0;32m     33\u001b[0m scrambled_chars_str \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,scrambled_token)\n\u001b[0;32m     34\u001b[0m pattern \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m[\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39mscrambled_chars_str\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m---> 35\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(re\u001b[39m.\u001b[39;49msub(pattern, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, scrambled_token)) \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:            \n\u001b[0;32m     36\u001b[0m     remaked \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(pattern, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m,scrambled_token)\n\u001b[0;32m     37\u001b[0m     df_scrambled_indx \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\regex\\regex.py:277\u001b[0m, in \u001b[0;36msub\u001b[1;34m(pattern, repl, string, count, flags, pos, endpos, concurrent, timeout, ignore_unused, **kwargs)\u001b[0m\n\u001b[0;32m    270\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msub\u001b[39m(pattern, repl, string, count\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, flags\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, pos\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, endpos\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    271\u001b[0m   concurrent\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, ignore_unused\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    272\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the string obtained by replacing the leftmost (or rightmost with a\u001b[39;00m\n\u001b[0;32m    273\u001b[0m \u001b[39m    reverse pattern) non-overlapping occurrences of the pattern in string by the\u001b[39;00m\n\u001b[0;32m    274\u001b[0m \u001b[39m    replacement repl. repl can be either a string or a callable; if a string,\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[39m    backslash escapes in it are processed; if a callable, it's passed the match\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[39m    object and must return a replacement string to be used.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     pat \u001b[39m=\u001b[39m _compile(pattern, flags, ignore_unused, kwargs, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    278\u001b[0m     \u001b[39mreturn\u001b[39;00m pat\u001b[39m.\u001b[39msub(repl, string, count, pos, endpos, concurrent, timeout)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\regex\\regex.py:546\u001b[0m, in \u001b[0;36m_compile\u001b[1;34m(pattern, flags, ignore_unused, kwargs, cache_it)\u001b[0m\n\u001b[0;32m    543\u001b[0m         caught_exception \u001b[39m=\u001b[39m e\n\u001b[0;32m    545\u001b[0m     \u001b[39mif\u001b[39;00m caught_exception:\n\u001b[1;32m--> 546\u001b[0m         \u001b[39mraise\u001b[39;00m error(caught_exception\u001b[39m.\u001b[39mmsg, caught_exception\u001b[39m.\u001b[39mpattern,\n\u001b[0;32m    547\u001b[0m           caught_exception\u001b[39m.\u001b[39mpos)\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m source\u001b[39m.\u001b[39mat_end():\n\u001b[0;32m    550\u001b[0m     \u001b[39mraise\u001b[39;00m error(\u001b[39m\"\u001b[39m\u001b[39munbalanced parenthesis\u001b[39m\u001b[39m\"\u001b[39m, pattern, source\u001b[39m.\u001b[39mpos)\n",
      "\u001b[1;31merror\u001b[0m: unterminated character set at position 2"
     ]
    }
   ],
   "source": [
    "# varsion 3\n",
    "\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def illegal_extractor(input_text, input_list, dict_out = True):\n",
    "    df_scrambled = pd.DataFrame(columns = ['remake', 'scrambled'])\n",
    "    input_text = input_text.replace('\\\\', '#')\n",
    "    tokens = input_text.split(' ')\n",
    "    \n",
    "    legal_tokens = []\n",
    "    scrambled_tokens = []\n",
    "    \n",
    "    # legal extraction\n",
    "    for token in tokens:\n",
    "        if len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 0:\n",
    "            scrambled_tokens.append(token)\n",
    "        elif len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 1:\n",
    "            legal_tokens.append(token)\n",
    "        else:\n",
    "            raise Exception(\"*** Error in legal_illegal extraction***\")            \n",
    "    \n",
    "    df_span = pd.DataFrame(columns = ['illegal', 'span'])\n",
    "    span_dict = {}\n",
    "    df_span_indx = -1\n",
    "    df_scrambled_indx = -1\n",
    "    \n",
    "    last_legal = {} # last index for last stored word for multiple same values\n",
    "    last_scrambled = {} # end index of last stored word for multiple same values\n",
    "    for scrambled_token in scrambled_tokens:\n",
    "        \n",
    "        scrambled_chars_str = re.sub('[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]', '',scrambled_token)\n",
    "        pattern = '['+scrambled_chars_str+']'\n",
    "        if len(re.sub(pattern, '', scrambled_token)) != 0:            \n",
    "            remaked = re.sub(pattern, '',scrambled_token)\n",
    "            df_scrambled_indx += 1\n",
    "            df_scrambled.loc[df_scrambled_indx] = (remaked, scrambled_token)\n",
    "    \n",
    "    # print(df_scrambled)    \n",
    "    for user_word in input_list:\n",
    "        if user_word in legal_tokens:\n",
    "            span_list = []\n",
    "            for _ in range(legal_tokens.count(user_word)):\n",
    "                start_search = 0\n",
    "                if user_word in last_legal.keys():\n",
    "                    start_search = last_legal[user_word]\n",
    "                start_index = input_text.find(user_word, start_search)\n",
    "                stop_index = start_index + len(user_word) - 1\n",
    "                last_legal[user_word] = stop_index\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "            \n",
    "            # print('after\\n',df_span, '\\n =====================')    \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "                # print('if\\n',df_span, '\\n =====================')  \n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "                # print('else\\n',df_span, '\\n =====================')  \n",
    "            \n",
    "        # elif --> changed to if --> word can be in both legal_tokens and scrambled   \n",
    "        if user_word in df_scrambled.remake.values:\n",
    "            span_list = []\n",
    "            for word in df_scrambled[df_scrambled.remake == user_word]['scrambled']:\n",
    "                start_search = 0\n",
    "                if word in last_scrambled.keys():\n",
    "                    start_search = last_scrambled[word]\n",
    "                start_index = input_text.find(word, start_search)\n",
    "                stop_index = start_index + len(word) - 1\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "                last_scrambled[word] = stop_index\n",
    "            \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "    \n",
    "    if not dict_out:\n",
    "        return df_span\n",
    "    \n",
    "    ## Turn dataframe to dict\n",
    "    for item in df_span.iterrows():\n",
    "        span_dict[item[1][0]] = item[1][1]\n",
    "    return span_dict\n",
    "    \n",
    "\n",
    "inputs = ['این قا#3dشق را فروختم.', \n",
    "          'با قا833gheشق و چن^گsd6yالg غذا خوردم.',\n",
    "         'من قاشق قاشق قاشق دارم.',\n",
    "         'من قاشق و قاشق،قاشق،قاشق را در جیب دارم.',\n",
    "         'من قا3شق و قا3شق را قاشق دارم.',\n",
    "         'قاشق من با قا///شق تو دوست است.',\n",
    "         'قاشق من چن\\\\u843گال هوایی میزند.',\n",
    "         'من قاشق         دوست قا*شق دارم.']\n",
    "\n",
    "for input in inputs:\n",
    "    print('='*50)\n",
    "    print(illegal_extractor(input,['چنگال','قاشق']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "ورژن ۴\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "در این ورژن یکی دیگر از مشکل های رجکس که وجود +- یا -+ در ورودی بود حل شده است به این صورت که اگر در ورودی در کلمه غیر مجاز +- یا -+ به اضافه یکی دیگر از کارکتر ها مانند $ در ورودی غیر مجاز باشد کد به مشکل برخورده که در این ورژن این مشکل نیز مرتفع شده است. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varsion 3\n",
    "\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def illegal_extractor(input_text, input_list, dict_out = True):\n",
    "    df_scrambled = pd.DataFrame(columns = ['remake', 'scrambled'])\n",
    "    if input_text.find('\\\\'):\n",
    "          input_text = input_text.replace('\\\\', '#')\n",
    "    elif input_text.find('\\\\\\\\'):\n",
    "          input_text = input_text.replace('\\\\\\\\', '#2')\n",
    "\n",
    "    if input_text.find('+-'):\n",
    "      input_text = input_text.replace('+-', '#2')\n",
    "    \n",
    "    elif input_text.find('-+'):\n",
    "      input_text = input_text.replace('+-', '#2')\n",
    "    tokens = input_text.split(' ')\n",
    "    \n",
    "    legal_tokens = []\n",
    "    scrambled_tokens = []\n",
    "    \n",
    "    # legal extraction\n",
    "    for token in tokens:\n",
    "        if len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 0:\n",
    "            scrambled_tokens.append(token)\n",
    "        elif len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 1:\n",
    "            legal_tokens.append(token)\n",
    "        else:\n",
    "            raise Exception(\"*** Error in legal_illegal extraction***\")            \n",
    "    \n",
    "    df_span = pd.DataFrame(columns = ['illegal', 'span'])\n",
    "    span_dict = {}\n",
    "    df_span_indx = -1\n",
    "    df_scrambled_indx = -1\n",
    "    \n",
    "    last_legal = {} # last index for last stored word for multiple same values\n",
    "    last_scrambled = {} # end index of last stored word for multiple same values\n",
    "    for scrambled_token in scrambled_tokens:\n",
    "        \n",
    "        scrambled_chars_str = re.sub('[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]', '',scrambled_token)\n",
    "        pattern = '['+scrambled_chars_str+']'\n",
    "        if len(re.sub(pattern, '', scrambled_token)) != 0:            \n",
    "            remaked = re.sub(pattern, '',scrambled_token)\n",
    "            df_scrambled_indx += 1\n",
    "            df_scrambled.loc[df_scrambled_indx] = (remaked, scrambled_token)\n",
    "    \n",
    "    # print(df_scrambled)    \n",
    "    for user_word in input_list:\n",
    "        if user_word in legal_tokens:\n",
    "            span_list = []\n",
    "            for _ in range(legal_tokens.count(user_word)):\n",
    "                start_search = 0\n",
    "                if user_word in last_legal.keys():\n",
    "                    start_search = last_legal[user_word]\n",
    "                start_index = input_text.find(user_word, start_search)\n",
    "                stop_index = start_index + len(user_word) - 1\n",
    "                last_legal[user_word] = stop_index\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "            \n",
    "            # print('after\\n',df_span, '\\n =====================')    \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "                # print('if\\n',df_span, '\\n =====================')  \n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "                # print('else\\n',df_span, '\\n =====================')  \n",
    "            \n",
    "        # elif --> changed to if --> word can be in both legal_tokens and scrambled   \n",
    "        if user_word in df_scrambled.remake.values:\n",
    "            span_list = []\n",
    "            for word in df_scrambled[df_scrambled.remake == user_word]['scrambled']:\n",
    "                start_search = 0\n",
    "                if word in last_scrambled.keys():\n",
    "                    start_search = last_scrambled[word]\n",
    "                start_index = input_text.find(word, start_search)\n",
    "                stop_index = start_index + len(word) - 1\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "                last_scrambled[word] = stop_index\n",
    "            \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "    \n",
    "    if not dict_out:\n",
    "        return df_span\n",
    "    \n",
    "    ## Turn dataframe to dict\n",
    "    for item in df_span.iterrows():\n",
    "        span_dict[item[1][0]] = item[1][1]\n",
    "    return span_dict\n",
    "    \n",
    "\n",
    "inputs = ['این قا#3dشق را فروختم.', \n",
    "          'با قا833gheشق و چن^گsd6yالg غذا خوردم.',\n",
    "         'من قاشق قاشق قاشق دارم.',\n",
    "         'من قاشق و قاشق،قاشق،قاشق را در جیب دارم.',\n",
    "         'من قا3شق و قا3شق را قاشق دارم.',\n",
    "         'قاشق من با قا///شق تو دوست است.',\n",
    "         'قاشق من چن\\\\u843گال هوایی میزند.',\n",
    "         'من قاشق         دوست قا*شق دارم.']\n",
    "\n",
    "for input in inputs:\n",
    "    print('='*50)\n",
    "    print(illegal_extractor(input,['چنگال','قاشق']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "ورژن ۵\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "        در این ورژن قابلیت شناسایی چندین اسپیس به کد اضافه شده است به این صورتکه اگر چندین اسپیس در ورودی غیر مجاز یا در متن ورودی وجود داشته باشد کد به مشگل برنخورده و قابلیت شناسایی و بر طرف کردن آن را داشته باشد\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "{'قاشق': [(4, 10)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 12)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6), (8, 11), (13, 16)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6)]}\n",
      "==================================================\n",
      "{'قاشق': [(20, 23), (3, 7), (11, 15)]}\n",
      "==================================================\n",
      "{'قاشق': [(0, 3), (11, 17)]}\n",
      "==================================================\n",
      "{'چنگال': [(8, 17)], 'قاشق': [(0, 3)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6), (21, 25)]}\n"
     ]
    }
   ],
   "source": [
    "# update 5\n",
    "\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def illegal_extractor(input_text, input_list, dict_out = True):\n",
    "    df_scrambled = pd.DataFrame(columns = ['remake', 'scrambled'])\n",
    "    if input_text.find('\\\\'):\n",
    "          input_text = input_text.replace('\\\\', '#')\n",
    "    elif input_text.find('\\\\\\\\'):\n",
    "          input_text = input_text.replace('\\\\\\\\', '#2')\n",
    "\n",
    "    if input_text.find('+-'):\n",
    "      input_text = input_text.replace('+-', '#2')\n",
    "    \n",
    "    elif input_text.find('-+'):\n",
    "      input_text = input_text.replace('+-', '#2')\n",
    "    tokens_pre = input_text.split(' ')\n",
    "    tokens = []\n",
    "    for token in tokens_pre:\n",
    "        if token != '':\n",
    "            tokens.append(token)\n",
    "            \n",
    "    \n",
    "    legal_tokens = []\n",
    "    scrambled_tokens = []\n",
    "    \n",
    "    # legal extraction\n",
    "    for token in tokens:\n",
    "        if len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 0:\n",
    "            scrambled_tokens.append(token)\n",
    "        elif len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 1:\n",
    "            legal_tokens.append(token)\n",
    "        else:\n",
    "            raise Exception(\"*** Error in legal_illegal extraction***\")            \n",
    "    \n",
    "    df_span = pd.DataFrame(columns = ['illegal', 'span'])\n",
    "    span_dict = {}\n",
    "    df_span_indx = -1\n",
    "    df_scrambled_indx = -1\n",
    "    \n",
    "    last_legal = {} # last index for last stored word for multiple same values\n",
    "    last_scrambled = {} # end index of last stored word for multiple same values\n",
    "    for scrambled_token in scrambled_tokens:\n",
    "        \n",
    "        scrambled_chars_str = re.sub('[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]', '',scrambled_token)\n",
    "        pattern = '['+scrambled_chars_str+']'\n",
    "        if len(re.sub(pattern, '', scrambled_token)) != 0:            \n",
    "            remaked = re.sub(pattern, '',scrambled_token)\n",
    "            df_scrambled_indx += 1\n",
    "            df_scrambled.loc[df_scrambled_indx] = (remaked, scrambled_token)\n",
    "    \n",
    "    # print(df_scrambled)    \n",
    "    for user_word in input_list:\n",
    "        if (user_word in legal_tokens) or ():\n",
    "            span_list = []\n",
    "            for _ in range(legal_tokens.count(user_word)):\n",
    "                start_search = 0\n",
    "                if user_word in last_legal.keys():\n",
    "                    start_search = last_legal[user_word]\n",
    "                start_index = input_text.find(user_word, start_search)\n",
    "                stop_index = start_index + len(user_word) - 1\n",
    "                last_legal[user_word] = stop_index\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "            \n",
    "            # print('after\\n',df_span, '\\n =====================')    \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "                # print('if\\n',df_span, '\\n =====================')  \n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "                # print('else\\n',df_span, '\\n =====================')  \n",
    "            \n",
    "        # elif --> changed to if --> word can be in both legal_tokens and scrambled   \n",
    "        if user_word in df_scrambled.remake.values:\n",
    "            span_list = []\n",
    "            for word in df_scrambled[df_scrambled.remake == user_word]['scrambled']:\n",
    "                start_search = 0\n",
    "                if word in last_scrambled.keys():\n",
    "                    start_search = last_scrambled[word]\n",
    "                start_index = input_text.find(word, start_search)\n",
    "                stop_index = start_index + len(word) - 1\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "                last_scrambled[word] = stop_index\n",
    "            \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "    \n",
    "    if not dict_out:\n",
    "        return df_span\n",
    "    \n",
    "    ## Turn dataframe to dict\n",
    "    for item in df_span.iterrows():\n",
    "        span_dict[item[1][0]] = item[1][1]\n",
    "    return span_dict\n",
    "\n",
    "\n",
    "\n",
    "inputs = ['این قا#3dشق را فروختم.', \n",
    "          'با قا833gheشق و چن^گsd6yالg غذا خوردم.',\n",
    "         'من قاشق قاشق قاشق دارم.',\n",
    "         'من قاشق و قاشق،قاشق،قاشق را در جیب دارم.',\n",
    "         'من قا3شق و قا3شق را قاشق دارم.',\n",
    "         'قاشق من با قا///شق تو دوست است.',\n",
    "         'قاشق من چن\\\\u843گال هوایی میزند.',\n",
    "         'من قاشق         دوست قا*شق دارم.']\n",
    "\n",
    "for input in inputs:\n",
    "    print('='*50)\n",
    "    print(illegal_extractor(input,['چنگال','قاشق']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "ورژن ۶\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "\t\t در این ورژن یکی  از مشکلاتی که کد قبل داشت که به این صورت بود اگر ما دو کلمه غیر مجاز یک شکل در ورودی داشته باشیم که یکی از ان ها به صورت سالم و دیگری به صورت خراب شده ظاهر شوند کد قبلی بعد از بازسازی کلمات ، کلمه دوم را نادیده میگرفت  که در این نسخه این مشکل مرتفع شده است\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "{'قاشق': [(4, 10)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 12)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6), (8, 11), (13, 16)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6)]}\n",
      "==================================================\n",
      "{'قاشق': [(20, 23), (3, 7), (11, 15)]}\n",
      "==================================================\n",
      "{'قاشق': [(0, 3), (11, 17)]}\n",
      "==================================================\n",
      "{'چنگال': [(8, 17)], 'قاشق': [(0, 3)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6), (21, 25)]}\n"
     ]
    }
   ],
   "source": [
    "# varsion 6\n",
    "\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def illegal_extractor(input_text, input_list, dict_out = True):\n",
    "    df_scrambled = pd.DataFrame(columns = ['remake', 'scrambled', 'single'])\n",
    "    input_text = input_text.replace('\\\\', '#')\n",
    "    tokens_pre = input_text.split(' ')\n",
    "    tokens = []\n",
    "    for token in tokens_pre:\n",
    "        if token != '':\n",
    "            tokens.append(token)\n",
    "            \n",
    "    \n",
    "    legal_tokens = []\n",
    "    scrambled_tokens = []\n",
    "    \n",
    "    # legal extraction\n",
    "    for token in tokens:\n",
    "        if len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 0:\n",
    "            scrambled_tokens.append(token)\n",
    "        elif len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 1:\n",
    "            legal_tokens.append(token)\n",
    "        else:\n",
    "            raise Exception(\"*** Error in legal_illegal extraction***\")            \n",
    "    \n",
    "    df_span = pd.DataFrame(columns = ['illegal', 'span'])\n",
    "    span_dict = {}\n",
    "    df_span_indx = -1\n",
    "    df_scrambled_indx = -1\n",
    "    \n",
    "    last_legal = {} # last index for last stored word for multiple same values\n",
    "    last_scrambled = {} # end index of last stored word for multiple same values\n",
    "    for scrambled_token in scrambled_tokens:\n",
    "        \n",
    "        scrambled_chars_str = re.sub('[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]', '',scrambled_token)\n",
    "        pattern = '['+scrambled_chars_str+']'\n",
    "        if len(re.sub(pattern, '', scrambled_token)) != 0:            \n",
    "            remaked = re.sub(pattern, '',scrambled_token)\n",
    "            df_scrambled_indx += 1\n",
    "            single = None\n",
    "            for word in input_list:\n",
    "                if remaked[0:len(word)] == word:\n",
    "                    single = word\n",
    "            df_scrambled.loc[df_scrambled_indx] = (remaked, scrambled_token, single)\n",
    "    \n",
    "    # print(df_scrambled) \n",
    "    \n",
    "    \n",
    "    for user_word in input_list:\n",
    "        if user_word in legal_tokens:\n",
    "            span_list = []\n",
    "            for _ in range(legal_tokens.count(user_word)):\n",
    "                start_search = 0\n",
    "                if user_word in last_legal.keys():\n",
    "                    start_search = last_legal[user_word]\n",
    "                start_index = input_text.find(user_word, start_search)\n",
    "                stop_index = start_index + len(user_word) - 1\n",
    "                last_legal[user_word] = stop_index\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "            \n",
    "            # print('after\\n',df_span, '\\n =====================')    \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "                # print('if\\n',df_span, '\\n =====================')  \n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "                # print('else\\n',df_span, '\\n =====================')  \n",
    "        \n",
    "        # elif --> changed to if --> word can be in both legal_tokens and scrambled \n",
    "        if user_word in df_scrambled.remake.values or user_word in df_scrambled.single.values:\n",
    "            span_list = []\n",
    "            for word in df_scrambled[df_scrambled.remake == user_word]['scrambled']:\n",
    "                start_search = 0\n",
    "                if word in last_scrambled.keys():\n",
    "                    start_search = last_scrambled[word]\n",
    "                start_index = input_text.find(word, start_search)\n",
    "                stop_index = start_index + len(word) - 1\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "                last_scrambled[word] = stop_index\n",
    "            \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "    \n",
    "    if not dict_out:\n",
    "        return df_span\n",
    "    \n",
    "    ## Turn dataframe to dict\n",
    "    for item in df_span.iterrows():\n",
    "        span_dict[item[1][0]] = item[1][1]\n",
    "    return span_dict\n",
    "\n",
    "\n",
    "inputs = ['این قا#3dشق را فروختم.', \n",
    "          'با قا833gheشق و چن^گsd6yالg غذا خوردم.',\n",
    "         'من قاشق قاشق قاشق دارم.',\n",
    "         'من قاشق و قاشق،قاشق،قاشق را در جیب دارم.',\n",
    "         'من قا3شق و قا3شق را قاشق دارم.',\n",
    "         'قاشق من با قا///شق تو دوست است.',\n",
    "         'قاشق من چن\\\\u843گال هوایی میزند.',\n",
    "         'من قاشق         دوست قا*شق دارم.']\n",
    "\n",
    "for input in inputs:\n",
    "    print('='*50)\n",
    "    print(illegal_extractor(input,['چنگال','قاشق']))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "توضیحات کد ورژن 7\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "\t\tدر خط ۳ تا ۵ کتابخانه های موردنیاز برای اجرای تابع فراخوانی میگردند.\n",
    "\t\t<br>\n",
    "\t\tتابع illegal_extractor با ۳ ورودی تعریف میشود که ورودی های آن به ترتیب متن ورودی، لیست کلمات غیرمجاز و نوع نمایش خروجی میباشد.\n",
    "\t\t<br>\n",
    "\t\tدر خط ۸ یک دیتافریم تعریف میکنیم برای ذخیره سازی داده های غیرمجاز و فرم ساده شده‌ی آن ها.\n",
    "\t\t<br>\n",
    "\t\tدر خط ۹ تا ۱۲ تمامی  حروف \\ را با # جایگزین میکنیم. چون \\ جزو کارکترهای مخصوص بوده و در فرآیند رجکس اخلال ایجاد میکند. همچنین دلیل آنکه \\\\ نوشته شده است این می باشد که خود تابع Input() پایتون هر \\ را به صورت \\\\ میگیرد. و به صورت خلاصه ما با \\های فرد مشکل داریم.\n",
    "\t\t<br>\n",
    "\t\tدر خط ۱۴ تا ۱۸ کارکتر های خاص دیگری که در فرایند رجکس اخلال ایجاد میکنند را با ## جایگزین کرده که در اجرای کد با این ورودی ها به مشکل برنخوریم.\n",
    "\t\t<br>\n",
    "\t\tدر خط ۱۹ الی ۲۳ مشکل وجود چند اسپیس پشت سر هم را حل میکنیم. و کلمات جمله را با استفاده از اسپیس به توکن های جدا تبدیل میکنیم و در لیست tokens ذخیره میکنیم.\n",
    "\t\t<br>\n",
    "\t\tدر خط ۳۰ تا ۳۶ با استفاده از رجکس حروف فارسی و را تشخیص میدهیم و کلمات بهم ریخته و درست را جداسازی میکنیم.\n",
    "\t\t<br>\n",
    "\t\tدر خط ۳۸ یک دیتا فریم تعریف شده که موقعیت مکانی داده های غیر مجاز  در آن ذخیره میشود \n",
    "\t\t<br>\n",
    "\t\tحلقه یfor در خط ۴۵ در میان تمامی کلمات بهم ریخته حرکت میکند و دیتا فریم داده های بهم ریخته را به همراه حالت بازسازی شده و ساده کلمات ذخیره میکند \n",
    "\t\t<br>\n",
    "\t\tحلقه خط ۶۰ حلقه ی اصلی برنامه می باشد که بررسی میکند کلمات غیر مجازی که در ورودی داده شده اند در لیست توکن های سالم و بهم ریخته ی متن وجود دارد یا خیر\n",
    "\t\t<br>\n",
    "\t\tاز خط ۶۱ الی ۷۹ کلمات سالم را بررسی میکنیم به این شکل که در ابتدا بر روی تمامی تعداد کلمات سالم پیمایش میکنیم و ایندکس شروع و پایان هر کدام را یافته و در لیست span_list ذخیره مینکیم . سپس برسی میکنیم که ایا این اولین کلمه سالم است یا خیر و مقدار ان کلمه را در دیتا فریم df_span اضافه میکنیم\n",
    "        <br>\n",
    "\t\t.حال به سراغ کلمات بهم ریخته می رویم \n",
    "\t\t<br>\n",
    "\t\tدر خط ۸۱ الی ۸۵ بررسی میکنیم که ایا کلمه ی بهم ریخته به صورت ساده است (قا۳شق) یا به صورت تکرار شونده (قا۳شق،قا۳شق )و متغیر فلگ را بر این اساس مقدار دهی میکنیم .\n",
    "\t\t<br>\n",
    "\t\tدر خط ۸۷ الی ۱۰۶ کد را به دو قسمت برای موارد ساده و تکرار شونده جدا میکنیم.روند بررسی برای هر دو حالت یکسان می باشد بر روی کلمات بهم ریخته پیمایش میکنیم (پیمایش به این دلیل است که ممکن است از یک کلمه ی یکسان چندین بار در جمله امده باشد) و در ستون مربوطه ی دیتافریم df_scrambled کلمه مورد نظر را بررسی کرده و محل ایندکس شروع و پایان ان را می یابیم.\n",
    "\t\t<br>\n",
    "\t\tدر خط ۱۰۸ تا ۱۱۲  برسی میکنیم که ایا این اولین کلمه بهم ریخته است یا خیر و مقدار ان کلمه را در دیتا فریم df_span ذخیره میکنیم \n",
    "\t\t<br>\n",
    "\t\tخط ۱۱۶ تا ۱۲۰ با توجه به ارگمان سوم تابع مشخص میشود که خروجی به شکل یک دیتا فریم چاپ شود یا به شکل یک دیکشنری\n",
    "\t\t<br>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "{'قاشق': [(4, 10)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 12)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6), (8, 11), (13, 16)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6), (10, 23)]}\n",
      "==================================================\n",
      "{'قاشق': [(20, 23), (3, 7), (11, 15)]}\n",
      "==================================================\n",
      "{'قاشق': [(0, 3), (11, 17)]}\n",
      "==================================================\n",
      "{'چنگال': [(8, 17)], 'قاشق': [(0, 3)]}\n",
      "==================================================\n",
      "{'قاشق': [(3, 6), (21, 25)]}\n"
     ]
    }
   ],
   "source": [
    "# varsion 7 \n",
    "\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "def illegal_extractor(input_text, input_list, dict_out = True):\n",
    "    df_scrambled = pd.DataFrame(columns = ['remake', 'scrambled', 'single'])\n",
    "    if input_text.find('\\\\'):\n",
    "          input_text = input_text.replace('\\\\', '#')\n",
    "    elif input_text.find('\\\\\\\\'):\n",
    "          input_text = input_text.replace('\\\\\\\\', '#2')\n",
    "\n",
    "    if input_text.find('+-'):\n",
    "      input_text = input_text.replace('+-', '#2')\n",
    "    \n",
    "    elif input_text.find('-+'):\n",
    "      input_text = input_text.replace('+-', '#2')\n",
    "    tokens_pre = input_text.split(' ')\n",
    "    tokens = []\n",
    "    for token in tokens_pre:\n",
    "        if token != '':\n",
    "            tokens.append(token)\n",
    "            \n",
    "    \n",
    "    legal_tokens = []\n",
    "    scrambled_tokens = []\n",
    "    \n",
    "    # legal extraction\n",
    "    for token in tokens:\n",
    "        if len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 0:\n",
    "            scrambled_tokens.append(token)\n",
    "        elif len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 1:\n",
    "            legal_tokens.append(token)\n",
    "        else:\n",
    "            raise Exception(\"*** Error in legal_illegal extraction***\")            \n",
    "    \n",
    "    df_span = pd.DataFrame(columns = ['illegal', 'span'])\n",
    "    span_dict = {}\n",
    "    df_span_indx = -1\n",
    "    df_scrambled_indx = -1\n",
    "    \n",
    "    last_legal = {} # last index for last stored word for multiple same values\n",
    "    last_scrambled = {} # end index of last stored word for multiple same values\n",
    "    for scrambled_token in scrambled_tokens:\n",
    "        \n",
    "        scrambled_chars_str = re.sub('[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]', '',scrambled_token)\n",
    "        pattern = '['+scrambled_chars_str+']'\n",
    "        if len(re.sub(pattern, '', scrambled_token)) != 0:            \n",
    "            remaked = re.sub(pattern, '',scrambled_token)\n",
    "            df_scrambled_indx += 1\n",
    "            single = None\n",
    "            for word in input_list:\n",
    "                if remaked[0:len(word)] == word:\n",
    "                    single = word\n",
    "            df_scrambled.loc[df_scrambled_indx] = (remaked, scrambled_token, single)\n",
    "    \n",
    "    # print(df_scrambled) \n",
    "    \n",
    "    \n",
    "    for user_word in input_list:\n",
    "        if user_word in legal_tokens:\n",
    "            span_list = []\n",
    "            for _ in range(legal_tokens.count(user_word)):\n",
    "                start_search = 0\n",
    "                if user_word in last_legal.keys():\n",
    "                    start_search = last_legal[user_word]\n",
    "                start_index = input_text.find(user_word, start_search)\n",
    "                stop_index = start_index + len(user_word) - 1\n",
    "                last_legal[user_word] = stop_index\n",
    "                span_list.append( (start_index, stop_index) )\n",
    "            \n",
    "            # print('after\\n',df_span, '\\n =====================')    \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "                # print('if\\n',df_span, '\\n =====================')  \n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "                # print('else\\n',df_span, '\\n =====================')  \n",
    "        \n",
    "        flag = '0'\n",
    "        if user_word in df_scrambled.single.values:\n",
    "            flag = 'single'\n",
    "        elif user_word in df_scrambled.remake.values:\n",
    "            flag = 'remake'\n",
    "        # elif --> changed to if --> word can be in both legal_tokens and scrambled \n",
    "        if flag == 'single' or flag == 'remake':\n",
    "            span_list = []\n",
    "            if flag == 'remake':\n",
    "                for word in df_scrambled[df_scrambled.remake == user_word]['scrambled']:\n",
    "                    start_search = 0\n",
    "                    if word in last_scrambled.keys():\n",
    "                        start_search = last_scrambled[word]\n",
    "                    start_index = input_text.find(word, start_search)\n",
    "                    stop_index = start_index + len(word) - 1\n",
    "                    span_list.append( (start_index, stop_index) )\n",
    "                    last_scrambled[word] = stop_index\n",
    "            elif flag == 'single':\n",
    "                for word in df_scrambled[df_scrambled.single == user_word]['scrambled']:\n",
    "                    start_search = 0\n",
    "                    if word in last_scrambled.keys():\n",
    "                        start_search = last_scrambled[word]\n",
    "                    start_index = input_text.find(word, start_search)\n",
    "                    stop_index = start_index + len(word) - 1\n",
    "                    span_list.append( (start_index, stop_index) )\n",
    "                    last_scrambled[word] = stop_index\n",
    "            \n",
    "            if user_word in df_span['illegal'].values:\n",
    "                df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "            else:\n",
    "                df_span_indx += 1\n",
    "                df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "    \n",
    "    if not dict_out:\n",
    "        return df_span\n",
    "    \n",
    "    ## Turn dataframe to dict\n",
    "    for item in df_span.iterrows():\n",
    "        span_dict[item[1][0]] = item[1][1]\n",
    "    return span_dict\n",
    "\n",
    "\n",
    "\n",
    "inputs = ['این قا#3dشق را فروختم.', \n",
    "          'با قا833gheشق و چن^گsd6yالg غذا خوردم.',\n",
    "         'من قاشق قاشق قاشق دارم.',\n",
    "         'من قاشق و قاشق،قاشق،قاشق را در جیب دارم.',\n",
    "         'من قا3شق و قا3شق را قاشق دارم.',\n",
    "         'قاشق من با قا///شق تو دوست است.',\n",
    "         'قاشق من چن\\\\u843گال هوایی میزند.',\n",
    "         'من قاشق         دوست قا*شق دارم.']\n",
    "\n",
    "for input in inputs:\n",
    "    print('='*50)\n",
    "    print(illegal_extractor(input,['چنگال','قاشق']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<center><font color=#0F9442 size=6 >\n",
    "        شما می توانید برای اجرا کد از اخرین نسخه آن که در پایین اورده شده است استفاده کنید\n",
    "        </font></center>\n",
    "\t\t<hr>\n",
    "\t\t</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p></p>\n",
    "<br />\n",
    "<div id=\"sec_intro\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=5>\n",
    "\t\t<font color=#FF7500 size=6>\n",
    "نسخه نهایی\n",
    "        </font>\n",
    "\t\t<hr>\n",
    "\t\t<br>\n",
    "\t\tدر این نسخه کد ورژن ۷ به صورت یک کلاس با تابع های مجزا نوشته شده است\n",
    "\t\t</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update OOP\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "\n",
    "class illegal_extractor:\n",
    "\n",
    "    def __init__(self, input_list):\n",
    "        self.input_list = input_list\n",
    "        \n",
    "    \n",
    "    def __tokenizer(self,input_text):\n",
    "        if input_text.find('\\\\'):\n",
    "          preprocessed_text = input_text.replace('\\\\', '#')\n",
    "        elif input_text.find('\\\\\\\\'):\n",
    "          preprocessed_text = input_text.replace('\\\\\\\\', '#2')\n",
    "\n",
    "        if input_text.find('+-'):\n",
    "         preprocessed_text = input_text.replace('+-', '#2')\n",
    "    \n",
    "        elif input_text.find('-+'):\n",
    "         preprocessed_text = input_text.replace('+-', '#2')\n",
    "\n",
    "        pre_tokens = preprocessed_text.split(' ')\n",
    "        tokens = []\n",
    "        for token in pre_tokens:\n",
    "            if token != '':\n",
    "                tokens.append(token)\n",
    "        \n",
    "        return tokens, preprocessed_text\n",
    "    \n",
    "    def __token_kinds(self, tokens):\n",
    "        # legal extraction\n",
    "        scrambled_tokens = []\n",
    "        legal_tokens = []\n",
    "        for token in tokens:\n",
    "            if len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 0:\n",
    "                scrambled_tokens.append(token)\n",
    "            elif len(re.findall('^[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]+$', token)) == 1:\n",
    "                legal_tokens.append(token)\n",
    "            else:\n",
    "                raise Exception(\"*** Error in legal_illegal extraction***\") \n",
    "                \n",
    "        return legal_tokens, scrambled_tokens\n",
    "        \n",
    "    def __remaker(self, scrambled_tokens):\n",
    "        df_scrambled = pd.DataFrame(columns = ['remake', 'scrambled', 'single'])\n",
    "        df_scrambled_indx = -1\n",
    "        \n",
    "        for scrambled_token in scrambled_tokens:\n",
    "            scrambled_chars_str = re.sub('[آابپتثجچحخدذرزژسشصضطظعغفقکگلمنوهی]', '',scrambled_token)\n",
    "            pattern = '['+scrambled_chars_str+']'\n",
    "            if len(re.sub(pattern, '', scrambled_token)) != 0:            \n",
    "                remaked = re.sub(pattern, '',scrambled_token)\n",
    "                single = None\n",
    "                for word in self.input_list:\n",
    "                    if remaked[0:len(word)] == word:\n",
    "                        single = word\n",
    "                \n",
    "                if single != None:\n",
    "                    df_scrambled_indx += 1\n",
    "                    df_scrambled.loc[df_scrambled_indx] = (remaked, scrambled_token, single)  \n",
    "                \n",
    "        return df_scrambled\n",
    "                        \n",
    "    def __span_extractor(self, legal_tokens, input_text, df_scrambled):\n",
    "        \n",
    "        df_span = pd.DataFrame(columns = ['illegal', 'span'])\n",
    "        df_span_indx = -1\n",
    "\n",
    "        last_legal = {} # last index for last stored word for multiple same values\n",
    "        last_scrambled = {} # end index of last stored word for multiple same values\n",
    "        \n",
    "        for user_word in self.input_list:\n",
    "            if user_word in legal_tokens:\n",
    "                span_list = []\n",
    "                for _ in range(legal_tokens.count(user_word)):\n",
    "                    start_search = 0\n",
    "                    if user_word in last_legal.keys():\n",
    "                        start_search = last_legal[user_word]\n",
    "                    start_index = input_text.find(user_word, start_search)\n",
    "                    stop_index = start_index + len(user_word) - 1\n",
    "                    last_legal[user_word] = stop_index\n",
    "                    span_list.append( (start_index, stop_index) )\n",
    "\n",
    "                if user_word in df_span['illegal'].values:\n",
    "                    df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "                else:\n",
    "                    df_span_indx += 1\n",
    "                    df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "                    \n",
    "            flag = ''\n",
    "            if user_word in df_scrambled.single.values:\n",
    "                flag = 'single'\n",
    "            elif user_word in df_scrambled.remake.values:\n",
    "                flag = 'remake'\n",
    "            # elif --> changed to if --> word can be in both legal_tokens and scrambled \n",
    "            if flag == 'single' or flag == 'remake':\n",
    "                span_list = []\n",
    "                if flag == 'remake':\n",
    "                    for word in df_scrambled[df_scrambled.remake == user_word]['scrambled']:\n",
    "                        start_search = 0\n",
    "                        if word in last_scrambled.keys():\n",
    "                            start_search = last_scrambled[word]\n",
    "                        start_index = input_text.find(word, start_search)\n",
    "                        stop_index = start_index + len(word) - 1\n",
    "                        span_list.append( (start_index, stop_index) )\n",
    "                        last_scrambled[word] = stop_index\n",
    "                elif flag == 'single':\n",
    "                    for word in df_scrambled[df_scrambled.single == user_word]['scrambled']:\n",
    "                        start_search = 0\n",
    "                        if word in last_scrambled.keys():\n",
    "                            start_search = last_scrambled[word]\n",
    "                        start_index = input_text.find(word, start_search)\n",
    "                        stop_index = start_index + len(word) - 1\n",
    "                        span_list.append( (start_index, stop_index) )\n",
    "                        last_scrambled[word] = stop_index\n",
    "\n",
    "                if user_word in df_span['illegal'].values:\n",
    "                    df_span[df_span['illegal'] == user_word]['span'].values[0] += span_list\n",
    "                else:\n",
    "                    df_span_indx += 1\n",
    "                    df_span.loc[df_span_indx] = (user_word, span_list)\n",
    "                    \n",
    "        return df_span\n",
    "        \n",
    "    def run(self, input_text, dict_out = True):\n",
    "        tokens,input_text = self.__tokenizer(input_text)\n",
    "        legal_tokens, scrambled_tokens= self.__token_kinds(tokens)\n",
    "        df_scrambled = self.__remaker(scrambled_tokens)\n",
    "        df_span = self.__span_extractor(legal_tokens, input_text, df_scrambled)\n",
    "        \n",
    "        if not dict_out:\n",
    "            return df_span\n",
    "        \n",
    "        span_dict = {}\n",
    "        ## Turn dataframe to dict\n",
    "        for item in df_span.iterrows():\n",
    "            span_dict[item[1][0]] = item[1][1]\n",
    "        return span_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final result:\n",
      "{'تفنگ': [(59, 62), (64, 67), (49, 57), (64, 74)], 'چاقو': [(101, 113), (115, 119), (161, 166)], 'قتل': [(132, 144)]}\n"
     ]
    }
   ],
   "source": [
    "#enter your illegal word here\n",
    "extractor = illegal_extractor(['تفنگ','چاقو', 'قتل'])\n",
    "#enter your input text here\n",
    "answer = extractor.run(''' باتوجه به خبری که امروز دیدم شخصی با استفاده از تف**342نگ تفنگ تفنگت&^%فنگ شخص دیگری که چا)()-+==قو چا###$%^$^Uقو چ+اقو داشت را به ق*)*)((ت##$$ل رساند ولی هنوز چا+-قو و تفنگ پیدا نشده‌اند ...))\n",
    "''')\n",
    "print(\"final result:\")\n",
    "print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
